<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>scrape &#8212; JHU Software Concepts - Module 5 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=8d563738"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for scrape</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;GradCafe scraping helpers for survey and result-page extraction.&quot;&quot;&quot;</span>

<span class="c1"># Approach: collect table rows first, then hydrate each row with detailed result-page fields.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">urllib</span><span class="w"> </span><span class="kn">import</span> <span class="n">error</span><span class="p">,</span> <span class="n">request</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">urllib.request</span><span class="w"> </span><span class="kn">import</span> <span class="n">urlopen</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>


<span class="n">BASE_URL</span> <span class="o">=</span> <span class="s1">&#39;https://www.thegradcafe.com&#39;</span>

<span class="c1"># 21 records per page should provide ~40k results</span>
<span class="n">NUM_PAGES_OF_DATA</span> <span class="o">=</span> <span class="mi">2000</span>

<span class="c1"># MAX_WORKERS = 10 is a safe &quot;polite&quot; starting point.</span>
<span class="c1"># Increase to 20 or 30 if the server handles it well.</span>
<span class="n">MAX_WORKERS</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Anything restricted by robots.txt</span>
<span class="n">DISALLOWED_PAGES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;/cgi-bin/&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;/index-ad-test.php&#39;</span><span class="p">]</span>

<span class="c1"># This header makes the scraper look like a standard Chrome browser</span>
<span class="n">HEADERS</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) </span><span class="se">\</span>
<span class="s1">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#39;</span>
<span class="p">}</span>

<span class="n">RESULT_FIELD_MAP</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;university&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;program&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;degree&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;US/International&#39;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;application status&#39;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s1">&#39;application status date&#39;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s1">&#39;GPA&#39;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s1">&#39;comments&#39;</span><span class="p">,</span>
<span class="p">}</span>


<div class="viewcode-block" id="_is_restricted_path">
<a class="viewcode-back" href="../api_scrape.html#scrape._is_restricted_path">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">_is_restricted_path</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check whether a URL path is disallowed by configured robots rules.</span>

<span class="sd">    :param url: Absolute URL to validate.</span>
<span class="sd">    :type url: str</span>
<span class="sd">    :returns: ``True`` when the URL contains a disallowed path prefix.</span>
<span class="sd">    :rtype: bool</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">restricted_path</span> <span class="ow">in</span> <span class="n">DISALLOWED_PAGES</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">restricted_path</span> <span class="ow">in</span> <span class="n">url</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span></div>



<div class="viewcode-block" id="_fetch_table_page">
<a class="viewcode-back" href="../api_scrape.html#scrape._fetch_table_page">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">_fetch_table_page</span><span class="p">(</span><span class="n">page_num</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fetch and parse a single ``/survey`` page.</span>

<span class="sd">    :param page_num: Survey page number to request.</span>
<span class="sd">    :type page_num: int</span>
<span class="sd">    :returns: Parsed rows from the table, grouped by record.</span>
<span class="sd">    :rtype: list[list[str]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">BASE_URL</span><span class="si">}</span><span class="s2">/survey/?page=</span><span class="si">{</span><span class="n">page_num</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="n">_is_restricted_path</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Create a Request object with the headers</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">HEADERS</span><span class="p">)</span>
        <span class="c1"># Use a timeout so the script doesn&#39;t hang forever</span>
        <span class="k">with</span> <span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="c1"># Create soup object from response bytes</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;table&#39;</span><span class="p">)</span>

        <span class="c1"># If nothing is found, return</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">table</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Get all rows after skipping the header row</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># Parse rows and combine the data from rows that are part of the same record</span>
        <span class="n">parsed_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">tmp_row</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
            <span class="c1"># A &lt;tr&gt; tag with no attrs indicates the first row of a new record</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">attrs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># If tmp_row contains data, store it in parsed_data then clear it</span>
                <span class="c1"># It is empty here when the very first row is being processed</span>
                <span class="k">if</span> <span class="n">tmp_row</span><span class="p">:</span>
                    <span class="n">parsed_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_row</span><span class="p">)</span>

                <span class="n">tmp_row</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Extract the information from the columns in each row</span>
            <span class="n">cells</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">row</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">)]</span>

            <span class="c1"># Find the link to the corresponding /result/{result_number} path</span>
            <span class="c1"># And insert it at index 0</span>
            <span class="n">link</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">link</span><span class="p">:</span>
                <span class="n">link</span> <span class="o">=</span> <span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
                <span class="n">tmp_row</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">link</span><span class="p">)</span>

            <span class="c1"># Add all gathered information in this row to tmp_row</span>
            <span class="n">tmp_row</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>

        <span class="c1"># Make sure the very last row of data is added to parsed_data</span>
        <span class="k">if</span> <span class="n">tmp_row</span><span class="p">:</span>
            <span class="n">parsed_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_row</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">parsed_data</span>

    <span class="k">except</span> <span class="n">error</span><span class="o">.</span><span class="n">HTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;HTTP Error </span><span class="si">{</span><span class="n">e</span><span class="o">.</span><span class="n">code</span><span class="si">}</span><span class="s2"> on page </span><span class="si">{</span><span class="n">page_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">except</span> <span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">URLError</span><span class="p">,</span> <span class="ne">TimeoutError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error on page </span><span class="si">{</span><span class="n">page_num</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span></div>



<div class="viewcode-block" id="_extract_result_num">
<a class="viewcode-back" href="../api_scrape.html#scrape._extract_result_num">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">_extract_result_num</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract integer result id from a result URL.</span>

<span class="sd">    :param url: URL containing a trailing result identifier segment.</span>
<span class="sd">    :type url: str</span>
<span class="sd">    :returns: Parsed result id or ``None`` when invalid.</span>
<span class="sd">    :rtype: int | None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">url</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span></div>



<div class="viewcode-block" id="_fetch_result_page">
<a class="viewcode-back" href="../api_scrape.html#scrape._fetch_result_page">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">_fetch_result_page</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">payload</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fetch one result page and populate a payload dictionary.</span>

<span class="sd">    :param url: Absolute result page URL.</span>
<span class="sd">    :type url: str</span>
<span class="sd">    :param payload: Existing payload map seeded from survey-table fields.</span>
<span class="sd">    :type payload: dict[str, str]</span>
<span class="sd">    :returns: Updated payload, or empty dict on failure.</span>
<span class="sd">    :rtype: dict[str, str]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Check for restricted URLs from robots.txt</span>
    <span class="k">if</span> <span class="n">_is_restricted_path</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="c1"># Getting page number in case of error to print the specific page</span>
    <span class="n">page_num</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Create a Request object with the headers</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">HEADERS</span><span class="p">)</span>
        <span class="c1"># Use a timeout so the script doesn&#39;t hang forever</span>
        <span class="k">with</span> <span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="c1"># Create soup object from response bytes</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

        <span class="c1"># Get all the data fields on the page</span>
        <span class="n">entries</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;dl&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">)</span>

        <span class="c1"># Return if nothing found</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">entries</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Parse the entries and store raw data in the payload dict, then return</span>
        <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;url&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">url</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">entry</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">entries</span><span class="p">):</span>
            <span class="n">field_name</span> <span class="o">=</span> <span class="n">RESULT_FIELD_MAP</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">field_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Check that the field has text content to avoid errors.</span>
                <span class="n">field_contents</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;dd&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">field_contents</span><span class="p">:</span>
                    <span class="n">payload</span><span class="p">[</span><span class="n">field_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">field_contents</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># The GRE scores have a slightly different format</span>
                <span class="n">field_contents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;li&#39;</span><span class="p">))</span>
                <span class="c1"># Quant/Verbal/AW values are nested under `&lt;li&gt;&lt;span&gt;..&lt;/span&gt;&lt;b&gt;..&lt;/b&gt;`.</span>
                <span class="n">spans</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">next_sibling</span><span class="o">.</span><span class="n">next_sibling</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">field_contents</span><span class="p">]</span>
                <span class="n">field_contents</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">spans</span><span class="p">]</span>
                <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;GRE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">field_contents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;GRE V&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">field_contents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;GRE AW&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">field_contents</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">payload</span>

    <span class="k">except</span> <span class="n">error</span><span class="o">.</span><span class="n">HTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;HTTP Error </span><span class="si">{</span><span class="n">e</span><span class="o">.</span><span class="n">code</span><span class="si">}</span><span class="s2"> on page </span><span class="si">{</span><span class="n">page_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{}</span>
    <span class="k">except</span> <span class="p">(</span>
        <span class="n">error</span><span class="o">.</span><span class="n">URLError</span><span class="p">,</span>
        <span class="ne">TimeoutError</span><span class="p">,</span>
        <span class="ne">ValueError</span><span class="p">,</span>
        <span class="ne">AttributeError</span><span class="p">,</span>
        <span class="ne">IndexError</span><span class="p">,</span>
        <span class="ne">TypeError</span><span class="p">,</span>
        <span class="ne">RuntimeError</span><span class="p">,</span>
    <span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error on page </span><span class="si">{</span><span class="n">page_num</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{}</span></div>



<div class="viewcode-block" id="_concurrent_scraper">
<a class="viewcode-back" href="../api_scrape.html#scrape._concurrent_scraper">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">_concurrent_scraper</span><span class="p">(</span><span class="n">worker_func</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">is_mapping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">all_payloads</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Execute scraping tasks concurrently and aggregate successful results.</span>

<span class="sd">    :param worker_func: Callable executed per task.</span>
<span class="sd">    :type worker_func: collections.abc.Callable</span>
<span class="sd">    :param tasks: Task iterable passed to worker function(s).</span>
<span class="sd">    :type tasks: collections.abc.Iterable</span>
<span class="sd">    :param is_mapping: Whether each task maps to ``all_payloads[task]`` arg pair.</span>
<span class="sd">    :type is_mapping: bool</span>
<span class="sd">    :param all_payloads: Payload lookup table used when ``is_mapping=True``.</span>
<span class="sd">    :type all_payloads: dict | None</span>
<span class="sd">    :returns: Combined worker outputs.</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">all_results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Set up ThreadPoolExecutor to handle each worker_func slightly differently</span>
    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="n">MAX_WORKERS</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_mapping</span><span class="p">:</span>
            <span class="c1"># Logic for _fetch_result_page</span>
            <span class="n">future_to_task</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">worker_func</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">all_payloads</span><span class="p">[</span><span class="n">u</span><span class="p">]):</span> <span class="n">u</span>
                <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">tasks</span>
                <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Logic for _fetch_table_page</span>
            <span class="n">future_to_task</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">worker_func</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span> <span class="n">t</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tasks</span>
                <span class="p">}</span>

        <span class="c1"># Collect results, print out any errors encountered and move on</span>
        <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">future_to_task</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Iterate futures directly; ordering is not important for downstream consumers.</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">data</span><span class="p">:</span>
                    <span class="c1"># Use extend for lists and append for dicts</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">all_results</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">all_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span>
                <span class="n">error</span><span class="o">.</span><span class="n">URLError</span><span class="p">,</span>
                <span class="ne">TimeoutError</span><span class="p">,</span>
                <span class="ne">ValueError</span><span class="p">,</span>
                <span class="ne">AttributeError</span><span class="p">,</span>
                <span class="ne">TypeError</span><span class="p">,</span>
                <span class="ne">RuntimeError</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">task</span> <span class="o">=</span> <span class="n">future_to_task</span><span class="p">[</span><span class="n">future</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2"> failed with: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">all_results</span></div>



<div class="viewcode-block" id="_get_raw_payloads">
<a class="viewcode-back" href="../api_scrape.html#scrape._get_raw_payloads">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">_get_raw_payloads</span><span class="p">(</span><span class="n">data_rows</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build full raw payloads from collected survey rows.</span>

<span class="sd">    The function seeds payloads from table rows, then fetches each linked result</span>
<span class="sd">    page to fill remaining fields.</span>

<span class="sd">    :param data_rows: Parsed survey table rows.</span>
<span class="sd">    :type data_rows: list[list[str]]</span>
<span class="sd">    :returns: Fully-populated payload dictionaries.</span>
<span class="sd">    :rtype: list[dict[str, str]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_payloads</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data_rows</span><span class="p">:</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;university&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;program&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;term&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;date added&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;url&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;application status&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;application status date&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;comments&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;US/International&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;GPA&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;GRE&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;GRE V&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;GRE AW&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span>
            <span class="p">}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># These are the only three entries needed from the table on /survey/</span>
            <span class="c1"># The rest of the fields are easier to parse from /result/ pages</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">BASE_URL</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;url&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">url</span>
            <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;date added&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
            <span class="n">payload</span><span class="p">[</span><span class="s1">&#39;term&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span>
            <span class="n">all_payloads</span><span class="p">[</span><span class="n">url</span><span class="p">]</span> <span class="o">=</span> <span class="n">payload</span>

        <span class="k">except</span> <span class="p">(</span><span class="ne">IndexError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
            <span class="c1"># Skip any malformed records</span>
            <span class="k">continue</span>

    <span class="c1"># Need the URL from the survey table to pull that particular result page and</span>
    <span class="c1"># gather the rest of the data for each record</span>
    <span class="n">all_urls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_payloads</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">all_results</span> <span class="o">=</span> <span class="n">_concurrent_scraper</span><span class="p">(</span><span class="n">_fetch_result_page</span><span class="p">,</span> <span class="n">all_urls</span><span class="p">,</span>
                                         <span class="n">is_mapping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">all_payloads</span><span class="o">=</span><span class="n">all_payloads</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FINAL RESULTS: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_results</span><span class="p">)</span><span class="si">}</span><span class="s2"> RECORDS PARSED SUCCESSFULLY&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">all_results</span></div>



<div class="viewcode-block" id="scrape_data">
<a class="viewcode-back" href="../api_scrape.html#scrape.scrape_data">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">scrape_data</span><span class="p">(</span><span class="n">min_result_num</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">existing_urls</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Scrape admissions records from GradCafe.</span>

<span class="sd">    :param min_result_num: Optional lower-bound result id filter.</span>
<span class="sd">    :type min_result_num: int | None</span>
<span class="sd">    :param existing_urls: Optional URL set to skip already-ingested records.</span>
<span class="sd">    :type existing_urls: set[str] | None</span>
<span class="sd">    :returns: Raw scraped payload list.</span>
<span class="sd">    :rtype: list[dict[str, str]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># Collect data from /survey/ pages</span>
    <span class="n">collected_rows</span> <span class="o">=</span> <span class="n">_concurrent_scraper</span><span class="p">(</span><span class="n">_fetch_table_page</span><span class="p">,</span>
                                         <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">NUM_PAGES_OF_DATA</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Then collect data from /result/ pages</span>
    <span class="k">if</span> <span class="n">min_result_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">existing_urls</span><span class="p">:</span>
        <span class="n">filtered_rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">existing_urls</span> <span class="o">=</span> <span class="n">existing_urls</span> <span class="ow">or</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">collected_rows</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">row</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">BASE_URL</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">result_num</span> <span class="o">=</span> <span class="n">_extract_result_num</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
            <span class="c1"># URL dedupe check handles reruns where source pages still contain old records.</span>
            <span class="k">if</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">existing_urls</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">min_result_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">result_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">result_num</span> <span class="o">&lt;</span> <span class="n">min_result_num</span><span class="p">:</span>
                    <span class="k">continue</span>
            <span class="n">filtered_rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
        <span class="n">collected_rows</span> <span class="o">=</span> <span class="n">filtered_rows</span>

    <span class="n">raw_payloads</span> <span class="o">=</span> <span class="n">_get_raw_payloads</span><span class="p">(</span><span class="n">collected_rows</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Print total number of records retrieved and time to execute, then return</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Collected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">raw_payloads</span><span class="p">)</span><span class="si">}</span><span class="s1"> raw payloads in </span><span class="si">{</span><span class="n">t2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1</span><span class="si">:</span><span class="s1">.02f</span><span class="si">}</span><span class="s1"> secs&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">raw_payloads</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">JHU Software Concepts - Module 5</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Setup &amp; Run Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operational_notes.html">Operational Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">Testing Guide</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2026, Max M. McKie.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 9.1.0</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>